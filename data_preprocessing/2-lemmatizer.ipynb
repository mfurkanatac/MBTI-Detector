{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Furkan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Furkan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatization and special character removal complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag, word_tokenize\n",
    "import re\n",
    "\n",
    "# Download the required NLTK resources\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "# Load the data from the CSV file into a pandas DataFrame\n",
    "data_df = pd.read_csv(\"filtered_data.csv\")\n",
    "\n",
    "# Replace NaN values in the \"post-comment\" column with an empty string\n",
    "data_df[\"post-comment\"].fillna(\"\", inplace=True)\n",
    "\n",
    "# Create a WordNet Lemmatizer object\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to lemmatize the text with correct POS tag\n",
    "def lemmatize_text_with_pos(text):\n",
    "    words = word_tokenize(text)  # Tokenize the text into individual words\n",
    "    tagged_words = pos_tag(words)  # Get POS tags for each word\n",
    "    lemmatized_words = []\n",
    "    for word, tag in tagged_words:\n",
    "        wntag = tag[0].lower()  # Get the first character of the POS tag (e.g., 'n' for noun)\n",
    "        wntag = wntag if wntag in ['a', 'r', 'n', 'v'] else None  # Map POS tag to WordNet tags\n",
    "        if not wntag:\n",
    "            lemma = word\n",
    "        else:\n",
    "            lemma = lemmatizer.lemmatize(word, wntag)\n",
    "        lemmatized_words.append(lemma)\n",
    "    return \" \".join(lemmatized_words)  # Join the lemmatized words back into a string\n",
    "\n",
    "# Function to remove special characters from the text\n",
    "def remove_special_characters(text):\n",
    "    # Define a regex pattern to match special characters (excluding alphanumeric and spaces)\n",
    "    pattern = r\"[^a-zA-Z0-9\\s]\"\n",
    "    # Use regex to remove special characters and return the cleaned text\n",
    "    cleaned_text = re.sub(pattern, \"\", text)\n",
    "    return cleaned_text\n",
    "\n",
    "# Apply the remove_special_characters function to the \"post-comment\" column and store the results in a new column \"cleaned-comment\"\n",
    "data_df[\"cleaned-comment\"] = data_df[\"post-comment\"].apply(remove_special_characters)\n",
    "\n",
    "# Apply the lemmatize_text_with_pos function to the \"cleaned-comment\" column and store the results in another new column \"lemmatized-comment\"\n",
    "data_df[\"lemmatized-comment\"] = data_df[\"cleaned-comment\"].apply(lemmatize_text_with_pos)\n",
    "\n",
    "print(\"Lemmatization and special character removal complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbti_types = ['ISTJ','ISFJ','INFJ','INTJ','ISTP','ISFP','INFP','INTP','ESTP','ESFP','ENFP','ENTP','ESTJ','ESFJ', 'ENFJ', 'ENTJ']\n",
    "\n",
    "\n",
    "# Create a mapping from MBTI types to numerical labels\n",
    "mbti_label_map = {mbti_type: idx for idx, mbti_type in enumerate(mbti_types)}\n",
    "\n",
    "# Convert MBTI types into numerical labels and store in a new column \"numerical-label\"\n",
    "data_df['numerical-label'] = data_df['flair'].map(mbti_label_map)\n",
    "\n",
    "data_df.drop(['cleaned-comment', \"post-comment\", \"username\", \"url\"], axis=1, inplace=True)\n",
    "\n",
    "# Write the DataFrame with lemmatized texts and numerical labels to a new CSV file\n",
    "data_df.to_csv(\"data_clean.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
